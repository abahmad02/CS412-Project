{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403eba8c",
   "metadata": {},
   "source": [
    "# Enhanced Sentiment Analysis of IMDB Movie Reviews\n",
    "\n",
    "This notebook performs advanced sentiment analysis on the IMDB movie review dataset with various improvements to boost accuracy and F1 scores.\n",
    "\n",
    "**Enhancements:**\n",
    "- Improved text preprocessing that preserves sentiment-critical features\n",
    "- Advanced feature engineering (n-grams, sentiment lexicon features)\n",
    "- Hyperparameter tuning for all models\n",
    "- Ensemble methods\n",
    "- Data augmentation techniques\n",
    "\n",
    "**Models:**\n",
    "- Optimized Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- BiLSTM with attention\n",
    "- RoBERTa (improved BERT variant)\n",
    "- Model Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4f2120",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef50160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick dataset exploration\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "print(df['sentiment'].value_counts(normalize=True).round(3))\n",
    "\n",
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(data=df, x='sentiment')\n",
    "plt.title(\"Sentiment Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Sentiment\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "\n",
    "# Add count and percentage labels\n",
    "total = len(df)\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width()/2.,\n",
    "            height + 300,\n",
    "            f'{height} ({height/total:.1%})',\n",
    "            ha=\"center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4074eb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review length analysis\n",
    "df['review_length'] = df['review'].apply(len)\n",
    "df['word_count'] = df['review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Summary statistics\n",
    "length_stats = df[['review_length', 'word_count']].describe()\n",
    "print(\"Review length statistics:\")\n",
    "print(length_stats)\n",
    "\n",
    "# Visualize distributions\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.histplot(data=df, x='review_length', bins=50, kde=True, ax=ax[0])\n",
    "ax[0].set_title(\"Review Length Distribution (Characters)\", fontsize=12)\n",
    "ax[0].set_xlabel(\"Character Count\", fontsize=10)\n",
    "ax[0].axvline(df['review_length'].mean(), color='red', linestyle='--', \n",
    "              label=f'Mean: {df[\"review_length\"].mean():.0f}')\n",
    "ax[0].axvline(df['review_length'].median(), color='green', linestyle='--', \n",
    "              label=f'Median: {df[\"review_length\"].median():.0f}')\n",
    "ax[0].legend()\n",
    "\n",
    "sns.histplot(data=df, x='word_count', bins=50, kde=True, ax=ax[1])\n",
    "ax[1].set_title(\"Word Count Distribution\", fontsize=12)\n",
    "ax[1].set_xlabel(\"Word Count\", fontsize=10)\n",
    "ax[1].axvline(df['word_count'].mean(), color='red', linestyle='--', \n",
    "              label=f'Mean: {df[\"word_count\"].mean():.0f}')\n",
    "ax[1].axvline(df['word_count'].median(), color='green', linestyle='--', \n",
    "              label=f'Median: {df[\"word_count\"].median():.0f}')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare review length by sentiment\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='sentiment', y='word_count')\n",
    "plt.title(\"Word Count by Sentiment\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9059f5",
   "metadata": {},
   "source": [
    "## 2. Advanced Text Preprocessing\n",
    "\n",
    "Traditional preprocessing may remove important sentiment indicators like negations, punctuation emphasis, and contractions. We'll implement an enhanced preprocessing pipeline that preserves these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8daa112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\musab\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: click in c:\\users\\musab\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\musab\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\musab\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\musab\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: requests in c:\\users\\musab\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\musab\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\musab\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\musab\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\musab\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\musab\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (2025.1.31)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 524.3/624.3 kB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 624.3/624.3 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment, textblob\n",
      "Successfully installed textblob-0.19.0 vaderSentiment-3.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install nltk textblob vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0280c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Musab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Musab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Musab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Musab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Musab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Musab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying preprocessing techniques...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Apply the different preprocessing techniques\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mApplying preprocessing techniques...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mbasic_processed\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreview\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasic_preprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33menhanced_processed\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m'\u001b[39m].apply(enhanced_preprocess)\n\u001b[32m    125\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcontext_processed\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m'\u001b[39m].apply(context_aware_preprocess)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Musab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Musab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Musab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Musab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Musab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mbasic_preprocess\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     26\u001b[39m text = text.lower()  \u001b[38;5;66;03m# Convert to lowercase\u001b[39;00m\n\u001b[32m     27\u001b[39m tokens = word_tokenize(text)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m tokens = [\u001b[43mlemmatizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \n\u001b[32m     29\u001b[39m           \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(word) > \u001b[32m2\u001b[39m]\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\stem\\wordnet.py:85\u001b[39m, in \u001b[36mWordNetLemmatizer.lemmatize\u001b[39m\u001b[34m(self, word, pos)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m, pos: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     61\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Lemmatize `word` by picking the shortest of the possible lemmas,\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m    using the wordnet corpus reader's built-in _morphy function.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[33;03m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     83\u001b[39m \u001b[33;03m    :return: The shortest lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     lemmas = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_morphy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key=\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\stem\\wordnet.py:39\u001b[39m, in \u001b[36mWordNetLemmatizer._morphy\u001b[39m\u001b[34m(self, form, pos, check_exceptions)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_morphy\u001b[39m(\u001b[38;5;28mself\u001b[39m, form, pos, check_exceptions=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m    _morphy() is WordNet's _morphy lemmatizer.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    It returns a list of all lemmas found in WordNet.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m    ['us', 'u']\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wordnet \u001b[38;5;28;01mas\u001b[39;00m wn\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m wn._morphy(form, pos, check_exceptions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Basic preprocessing (similar to original notebook)\n",
    "def basic_preprocess(text):\n",
    "    \"\"\"Basic preprocessing that removes most punctuation and stopwords\"\"\"\n",
    "    text = re.sub('<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)  # Keep only letters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens \n",
    "              if word not in stop_words and len(word) > 2]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Enhanced preprocessing that preserves sentiment information\n",
    "def enhanced_preprocess(text):\n",
    "    \"\"\"Enhanced preprocessing that preserves sentiment information\"\"\"\n",
    "    # Remove HTML tags\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    \n",
    "    # Convert to lowercase but preserve certain patterns\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace repeated punctuation with special tokens\n",
    "    text = re.sub(r'([!?]){2,}', r'\\1 <EMPHASIS>', text)\n",
    "    \n",
    "    # Preserve negations and contractions\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"'m\", \" am\", text)\n",
    "    text = re.sub(r\"'s\", \" is\", text)\n",
    "    text = re.sub(r\"'re\", \" are\", text)\n",
    "    text = re.sub(r\"'ll\", \" will\", text)\n",
    "    text = re.sub(r\"'ve\", \" have\", text)\n",
    "    text = re.sub(r\"'d\", \" would\", text)\n",
    "    \n",
    "    # Replace remaining punctuation with space\n",
    "    text = re.sub(f'[{re.escape(string.punctuation)}]', ' ', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Define sentiment-important words to keep (even if they're in stopwords)\n",
    "    sentiment_words = {'no', 'not', 'never', 'none', 'nothing', 'nowhere', 'neither', \n",
    "                       'barely', 'hardly', 'rarely', 'seldom', 'despite', 'without',\n",
    "                       'very', 'too', 'but', 'however', 'although', 'though', 'except'}\n",
    "    \n",
    "    # Filter tokens (removing stopwords except sentiment words)\n",
    "    filtered_stop_words = {word for word in stop_words if word not in sentiment_words}\n",
    "    \n",
    "    # Lemmatize and join\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens \n",
    "              if word not in filtered_stop_words and len(word) > 1]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Context-aware preprocessing that considers n-grams for negations\n",
    "def context_aware_preprocess(text):\n",
    "    \"\"\"Preprocessing that keeps negation contexts intact\"\"\"\n",
    "    # Remove HTML\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    \n",
    "    # Replace contractions\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"'m\", \" am\", text)\n",
    "    text = re.sub(r\"'s\", \" is\", text)\n",
    "    text = re.sub(r\"'re\", \" are\", text)\n",
    "    text = re.sub(r\"'ll\", \" will\", text)\n",
    "    text = re.sub(r\"'ve\", \" have\", text)\n",
    "    text = re.sub(r\"'d\", \" would\", text)\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Handle negations by marking words that follow negation terms\n",
    "    negation_terms = {'no', 'not', 'never', 'none', 'nothing', 'nowhere', 'neither', \n",
    "                      'without', 'hardly', 'rarely', 'seldom', 'cannot', 'cant'}\n",
    "    \n",
    "    # Flag to track if we're in a negation context\n",
    "    in_negation = False\n",
    "    processed_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Check for punctuation that ends negation context\n",
    "        if token in {'.', '!', '?', ';', ':', ','}:\n",
    "            in_negation = False\n",
    "            continue\n",
    "            \n",
    "        # Check if token is a negation term\n",
    "        if token.lower() in negation_terms:\n",
    "            in_negation = True\n",
    "            processed_tokens.append(token)\n",
    "        else:\n",
    "            # If in negation context, mark the token\n",
    "            if in_negation and token not in stop_words and len(token) > 1:\n",
    "                processed_tokens.append(\"NEG_\" + lemmatizer.lemmatize(token))\n",
    "            elif token not in stop_words and len(token) > 1:\n",
    "                processed_tokens.append(lemmatizer.lemmatize(token))\n",
    "    \n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "# Apply the different preprocessing techniques\n",
    "print(\"Applying preprocessing techniques...\")\n",
    "df['basic_processed'] = df['review'].apply(basic_preprocess)\n",
    "df['enhanced_processed'] = df['review'].apply(enhanced_preprocess)\n",
    "df['context_processed'] = df['review'].apply(context_aware_preprocess)\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\nPreprocessing comparison for a sample review:\")\n",
    "sample_idx = df[df['review'].str.contains('not', case=False)].index[0]\n",
    "print(f\"Original: {df.loc[sample_idx, 'review'][:300]}...\")\n",
    "print(f\"\\nBasic: {df.loc[sample_idx, 'basic_processed'][:150]}...\")\n",
    "print(f\"\\nEnhanced: {df.loc[sample_idx, 'enhanced_processed'][:150]}...\")\n",
    "print(f\"\\nContext-aware: {df.loc[sample_idx, 'context_processed'][:150]}...\")\n",
    "\n",
    "# Map sentiment labels\n",
    "df['sentiment_label'] = df['sentiment'].map({'negative': 0, 'positive': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c2d65",
   "metadata": {},
   "source": [
    "## 3. Advanced Feature Engineering\n",
    "\n",
    "We'll extract additional features from the text that can help the models capture more sentiment information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af2f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Add sentiment lexicon-based features\n",
    "def extract_sentiment_features(text):\n",
    "    \"\"\"Extract sentiment scores using various libraries\"\"\"\n",
    "    # VADER sentiment\n",
    "    vader_scores = vader.polarity_scores(text)\n",
    "    \n",
    "    # TextBlob sentiment\n",
    "    blob = TextBlob(text)\n",
    "    textblob_polarity = blob.sentiment.polarity\n",
    "    textblob_subjectivity = blob.sentiment.subjectivity\n",
    "    \n",
    "    # Count specific features\n",
    "    exclamation_count = text.count('!')\n",
    "    question_count = text.count('?')\n",
    "    uppercase_ratio = sum(1 for c in text if c.isupper()) / (len(text) + 1)\n",
    "    \n",
    "    return {\n",
    "        'vader_neg': vader_scores['neg'],\n",
    "        'vader_neu': vader_scores['neu'],\n",
    "        'vader_pos': vader_scores['pos'],\n",
    "        'vader_compound': vader_scores['compound'],\n",
    "        'textblob_polarity': textblob_polarity,\n",
    "        'textblob_subjectivity': textblob_subjectivity,\n",
    "        'exclamation_count': min(exclamation_count, 5),  # Cap at 5 to avoid extreme values\n",
    "        'question_count': min(question_count, 5),\n",
    "        'uppercase_ratio': uppercase_ratio,\n",
    "        'review_length': len(text),\n",
    "        'word_count': len(text.split())\n",
    "    }\n",
    "\n",
    "# Extract all these features\n",
    "print(\"Extracting sentiment features...\")\n",
    "sentiment_features = df['review'].apply(extract_sentiment_features)\n",
    "\n",
    "# Convert to DataFrame and merge with main DataFrame\n",
    "sentiment_df = pd.DataFrame(sentiment_features.tolist())\n",
    "df = pd.concat([df, sentiment_df], axis=1)\n",
    "\n",
    "# Display correlation with sentiment\n",
    "sentiment_corr = df[[\n",
    "    'sentiment_label', 'vader_neg', 'vader_neu', 'vader_pos', 'vader_compound',\n",
    "    'textblob_polarity', 'textblob_subjectivity', 'exclamation_count', \n",
    "    'question_count', 'uppercase_ratio', 'word_count'\n",
    "]].corr()['sentiment_label'].sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nCorrelation of features with sentiment:\")\n",
    "print(sentiment_corr)\n",
    "\n",
    "# Visualize correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sentiment_corr = sentiment_corr.drop('sentiment_label')  # Remove self-correlation\n",
    "sns.barplot(x=sentiment_corr.index, y=sentiment_corr.values)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Feature Correlation with Sentiment Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5029770c",
   "metadata": {},
   "source": [
    "## 4. Data Splitting and Feature Extraction\n",
    "\n",
    "We'll use stratified splits and extract different sets of features to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf073f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split data\n",
    "X_raw = df['review']\n",
    "X_basic = df['basic_processed']\n",
    "X_enhanced = df['enhanced_processed']\n",
    "X_context = df['context_processed']\n",
    "y = df['sentiment_label']\n",
    "\n",
    "# Create numeric feature matrix\n",
    "numeric_features = [\n",
    "    'vader_neg', 'vader_neu', 'vader_pos', 'vader_compound',\n",
    "    'textblob_polarity', 'textblob_subjectivity', 'exclamation_count',\n",
    "    'question_count', 'uppercase_ratio', 'word_count'\n",
    "]\n",
    "X_numeric = df[numeric_features].values\n",
    "\n",
    "# Split using stratification to maintain class balance\n",
    "X_raw_train, X_raw_test, X_basic_train, X_basic_test, X_enhanced_train, X_enhanced_test, \\\n",
    "X_context_train, X_context_test, X_numeric_train, X_numeric_test, y_train, y_test = \\\n",
    "    train_test_split(\n",
    "        X_raw, X_basic, X_enhanced, X_context, X_numeric, y, \n",
    "        test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "# Create TF-IDF features with different configurations\n",
    "print(\"Creating TF-IDF features...\")\n",
    "\n",
    "# Basic TF-IDF (unigrams only, as in original)\n",
    "basic_tfidf = TfidfVectorizer(max_features=20000)\n",
    "X_basic_tfidf_train = basic_tfidf.fit_transform(X_basic_train)\n",
    "X_basic_tfidf_test = basic_tfidf.transform(X_basic_test)\n",
    "\n",
    "# N-gram TF-IDF with enhanced preprocessing (unigrams and bigrams)\n",
    "ngram_tfidf = TfidfVectorizer(\n",
    "    max_features=30000,\n",
    "    ngram_range=(1, 2),  # Include both unigrams and bigrams\n",
    "    min_df=5  # Minimum document frequency\n",
    ")\n",
    "X_enhanced_tfidf_train = ngram_tfidf.fit_transform(X_enhanced_train)\n",
    "X_enhanced_tfidf_test = ngram_tfidf.transform(X_enhanced_test)\n",
    "\n",
    "# Context-aware TF-IDF (includes negation-marked words)\n",
    "context_tfidf = TfidfVectorizer(\n",
    "    max_features=30000,\n",
    "    ngram_range=(1, 3),  # Include up to trigrams to capture more context\n",
    "    min_df=3\n",
    ")\n",
    "X_context_tfidf_train = context_tfidf.fit_transform(X_context_train)\n",
    "X_context_tfidf_test = context_tfidf.transform(X_context_test)\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_numeric_train_scaled = scaler.fit_transform(X_numeric_train)\n",
    "X_numeric_test_scaled = scaler.transform(X_numeric_test)\n",
    "\n",
    "# Print feature dimensions\n",
    "print(f\"Basic TF-IDF features: {X_basic_tfidf_train.shape}\")\n",
    "print(f\"Enhanced N-gram TF-IDF features: {X_enhanced_tfidf_train.shape}\")\n",
    "print(f\"Context-aware TF-IDF features: {X_context_tfidf_train.shape}\")\n",
    "print(f\"Numeric features: {X_numeric_train_scaled.shape}\")\n",
    "\n",
    "# Sample of top features\n",
    "print(\"\\nTop features from enhanced n-gram TF-IDF:\")\n",
    "feature_names = ngram_tfidf.get_feature_names_out()\n",
    "tfidf_sorting = np.argsort(X_enhanced_tfidf_train.toarray().sum(axis=0))[::-1]\n",
    "top_features = [feature_names[i] for i in tfidf_sorting[:20]]\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e0d21",
   "metadata": {},
   "source": [
    "## 5. Advanced Model Training with 5-Fold Cross-Validation\n",
    "\n",
    "We'll train multiple models with 5-fold cross-validation to get more reliable performance estimates. This gives us a better understanding of how our models will perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2bc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, make_scorer\n",
    "from scipy.sparse import hstack, vstack\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set number of cross-validation folds\n",
    "N_FOLDS = 5\n",
    "CV_RANDOM_STATE = 42\n",
    "\n",
    "# Function to perform cross-validation and evaluate a model\n",
    "def cv_evaluate_model(model, X, y, feature_type, model_name):\n",
    "    \"\"\"\n",
    "    Performs 5-fold cross validation on the model and returns performance metrics\n",
    "    \n",
    "    Parameters:\n",
    "    model - The model to evaluate\n",
    "    X - Feature matrix\n",
    "    y - Target variable\n",
    "    feature_type - Description of features used (for reporting)\n",
    "    model_name - Name of the model (for reporting)\n",
    "    \n",
    "    Returns:\n",
    "    model - The trained model (trained on full dataset)\n",
    "    cv_accuracy - Mean cross-validation accuracy\n",
    "    cv_f1 - Mean cross-validation F1 score\n",
    "    \"\"\"\n",
    "    # Define scorers for multiple metrics\n",
    "    scorers = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "        'precision_macro': make_scorer(precision_score, average='macro'),\n",
    "        'recall_macro': make_scorer(recall_score, average='macro')\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Set up stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=CV_RANDOM_STATE)\n",
    "    \n",
    "    # Perform cross-validation with multiple metrics\n",
    "    cv_results = cross_validate(\n",
    "        model, X, y, \n",
    "        cv=skf, \n",
    "        scoring=scorers, \n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Calculate training time\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Extract scores\n",
    "    cv_accuracy = cv_results['test_accuracy'].mean()\n",
    "    cv_f1 = cv_results['test_f1_macro'].mean()\n",
    "    cv_precision = cv_results['test_precision_macro'].mean()\n",
    "    cv_recall = cv_results['test_recall_macro'].mean()\n",
    "    \n",
    "    # Calculate standard deviations to report variability\n",
    "    cv_accuracy_std = cv_results['test_accuracy'].std()\n",
    "    cv_f1_std = cv_results['test_f1_macro'].std()\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results (with {feature_type}):\")\n",
    "    print(f\"Cross-validation time: {train_time:.2f} seconds\")\n",
    "    print(f\"CV Accuracy: {cv_accuracy:.4f} (±{cv_accuracy_std:.4f})\")\n",
    "    print(f\"CV Macro F1 Score: {cv_f1:.4f} (±{cv_f1_std:.4f})\")\n",
    "    print(f\"CV Macro Precision: {cv_precision:.4f}\")\n",
    "    print(f\"CV Macro Recall: {cv_recall:.4f}\")\n",
    "    \n",
    "    # Train on full dataset for later use (like in ensembles)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model, cv_accuracy, cv_f1\n",
    "\n",
    "# Combine all data for cross-validation (we won't use separate test set now)\n",
    "# Combine training and testing data for cross-validation\n",
    "X_basic_combined = vstack([X_basic_tfidf_train, X_basic_tfidf_test])\n",
    "X_enhanced_combined = vstack([X_enhanced_tfidf_train, X_enhanced_tfidf_test])\n",
    "X_context_combined = vstack([X_context_tfidf_train, X_context_tfidf_test])\n",
    "\n",
    "# Combine numeric features\n",
    "X_numeric_all = np.vstack([X_numeric_train_scaled, X_numeric_test_scaled])\n",
    "\n",
    "# Full feature matrices\n",
    "X_basic_full = hstack([X_basic_combined, X_numeric_all])\n",
    "X_enhanced_full = hstack([X_enhanced_combined, X_numeric_all])\n",
    "X_context_full = hstack([X_context_combined, X_numeric_all])\n",
    "\n",
    "# Combine target variables\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "print(f\"Full dataset dimensions:\")\n",
    "print(f\"Basic features: {X_basic_full.shape}\")\n",
    "print(f\"Enhanced features: {X_enhanced_full.shape}\")\n",
    "print(f\"Context-aware features: {X_context_full.shape}\")\n",
    "print(f\"Total samples: {len(y_full)}\")\n",
    "\n",
    "# 1. Optimized Logistic Regression with Grid Search\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Optimized Logistic Regression with 5-fold CV...\")\n",
    "lr_param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0, 100.0],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [1000],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),\n",
    "    param_grid=lr_param_grid,\n",
    "    cv=N_FOLDS,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on enhanced features\n",
    "lr_grid.fit(X_enhanced_full, y_full)\n",
    "print(f\"Best parameters: {lr_grid.best_params_}\")\n",
    "print(f\"Best CV score: {lr_grid.best_score_:.4f}\")\n",
    "\n",
    "# Get the optimized model\n",
    "optimized_lr = lr_grid.best_estimator_\n",
    "\n",
    "# Evaluate with the best model\n",
    "lr_model, lr_accuracy, lr_f1 = cv_evaluate_model(\n",
    "    optimized_lr,\n",
    "    X_enhanced_full, y_full,\n",
    "    \"Enhanced Features\",\n",
    "    \"Optimized Logistic Regression\"\n",
    ")\n",
    "\n",
    "# 2. Random Forest Classifier\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Random Forest Classifier with 5-fold CV...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model, rf_accuracy, rf_f1 = cv_evaluate_model(\n",
    "    rf_model,\n",
    "    X_context_full, y_full,\n",
    "    \"Context-aware Features\",\n",
    "    \"Random Forest Classifier\"\n",
    ")\n",
    "\n",
    "# 3. XGBoost Classifier\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training XGBoost Classifier with 5-fold CV...\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model, xgb_accuracy, xgb_f1 = cv_evaluate_model(\n",
    "    xgb_model,\n",
    "    X_enhanced_full, y_full,\n",
    "    \"Enhanced Features\",\n",
    "    \"XGBoost Classifier\"\n",
    ")\n",
    "\n",
    "# 4. Support Vector Machine\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Linear SVM with 5-fold CV...\")\n",
    "svm_model = LinearSVC(\n",
    "    C=1.0,\n",
    "    loss='hinge',\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "svm_model, svm_accuracy, svm_f1 = cv_evaluate_model(\n",
    "    svm_model,\n",
    "    X_basic_full, y_full,\n",
    "    \"Basic Features\",\n",
    "    \"Linear SVM\"\n",
    ")\n",
    "\n",
    "# Compare all models\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model Comparison (5-fold Cross-Validation):\")\n",
    "models = [\"Logistic Regression\", \"Random Forest\", \"XGBoost\", \"Linear SVM\"]\n",
    "accuracies = [lr_accuracy, rf_accuracy, xgb_accuracy, svm_accuracy]\n",
    "f1_scores = [lr_f1, rf_f1, xgb_f1, svm_f1]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'CV Accuracy': accuracies,\n",
    "    'CV F1 Score': f1_scores\n",
    "}).sort_values('CV F1 Score', ascending=False)\n",
    "\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "bars1 = ax.bar(x - width/2, accuracies, width, label='CV Accuracy')\n",
    "bars2 = ax.bar(x + width/2, f1_scores, width, label='CV F1 Score')\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'{height:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.set_ylim([0.75, 1.0])  # Adjust based on your actual results\n",
    "ax.legend()\n",
    "ax.set_title('Traditional ML Model Performance Comparison (5-fold CV)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f0a03",
   "metadata": {},
   "source": [
    "## 6. Enhanced Deep Learning Models with K-Fold Cross-Validation\n",
    "\n",
    "We'll implement advanced deep learning models and evaluate them using cross-validation for more reliable performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe44a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages\n",
    "!pip install tensorflow transformers torch sentencepiece tensorboard scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1568d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Attention, MultiHeadAttention, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Enable mixed precision (speeds up training on compatible GPUs)\n",
    "try:\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_global_policy(policy)\n",
    "    print(f'Compute dtype: {policy.compute_dtype}')\n",
    "    print(f'Variable dtype: {policy.variable_dtype}')\n",
    "except:\n",
    "    print(\"Mixed precision not supported in this TensorFlow version. Continuing with default precision.\")\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_WORDS = 25000  # Increased vocabulary size\n",
    "MAX_LEN = 250\n",
    "EMBEDDING_DIM = 100\n",
    "GLOVE_FILE_PATH = 'glove.6B.100d.txt'\n",
    "N_FOLDS = 5  # Same number of folds as traditional models\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5  # Reduced for faster cross-validation\n",
    "\n",
    "# Process all text data for deep learning cross-validation\n",
    "X_all_text = pd.concat([X_enhanced_train, X_enhanced_test])\n",
    "\n",
    "# Create tokenizer on all data\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_all_text)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_sequences_all = tokenizer.texts_to_sequences(X_all_text)\n",
    "\n",
    "# Pad sequences\n",
    "X_padded_all = pad_sequences(X_sequences_all, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Combine numeric features for deep learning\n",
    "X_numeric_all_np = np.vstack([X_numeric_train_scaled, X_numeric_test_scaled])\n",
    "\n",
    "# Load GloVe embeddings (if available)\n",
    "print(f\"Attempting to load GloVe embeddings from: {GLOVE_FILE_PATH}\")\n",
    "embeddings_index = {}\n",
    "embedding_matrix = None\n",
    "try:\n",
    "    with open(GLOVE_FILE_PATH, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f\"Successfully found {len(embeddings_index)} word vectors in GloVe file.\")\n",
    "\n",
    "    # Create embedding matrix\n",
    "    embedding_matrix = np.zeros((MAX_WORDS + 1, EMBEDDING_DIM))  # +1 for <OOV> token\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i > MAX_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print(\"Embedding matrix prepared.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"GloVe file not found at '{GLOVE_FILE_PATH}'. Will use random embeddings.\")\n",
    "    embedding_matrix = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading GloVe: {e}\")\n",
    "    embedding_matrix = None\n",
    "\n",
    "# 1. BiLSTM with Attention using K-fold cross-validation\n",
    "def build_bilstm_attention_model():\n",
    "    \"\"\"Build BiLSTM model with attention mechanism\"\"\"\n",
    "    # Text input\n",
    "    text_input = Input(shape=(MAX_LEN,), name='text_input')\n",
    "    \n",
    "    # Embedding layer\n",
    "    if embedding_matrix is not None:\n",
    "        embedding_layer = Embedding(\n",
    "            input_dim=MAX_WORDS + 1,  \n",
    "            output_dim=EMBEDDING_DIM,\n",
    "            weights=[embedding_matrix],\n",
    "            input_length=MAX_LEN,\n",
    "            trainable=True,  # Fine-tune embeddings\n",
    "            name='embedding'\n",
    "        )(text_input)\n",
    "    else:\n",
    "        embedding_layer = Embedding(\n",
    "            input_dim=MAX_WORDS + 1,\n",
    "            output_dim=EMBEDDING_DIM,\n",
    "            input_length=MAX_LEN,\n",
    "            trainable=True,\n",
    "            name='embedding'\n",
    "        )(text_input)\n",
    "    \n",
    "    # Bidirectional LSTM with attention\n",
    "    lstm_layer = Bidirectional(LSTM(128, return_sequences=True))(embedding_layer)\n",
    "    lstm_layer = Dropout(0.3)(lstm_layer)\n",
    "    \n",
    "    # Add attention mechanism\n",
    "    attention_layer = MultiHeadAttention(\n",
    "        num_heads=8, \n",
    "        key_dim=32,\n",
    "        dropout=0.1\n",
    "    )(lstm_layer, lstm_layer)\n",
    "    \n",
    "    # Add skip connection and layer normalization (transformer-style)\n",
    "    attention_layer = LayerNormalization()(lstm_layer + attention_layer)\n",
    "    \n",
    "    # Global pooling\n",
    "    max_pool = GlobalMaxPooling1D()(attention_layer)\n",
    "    avg_pool = GlobalAveragePooling1D()(attention_layer)\n",
    "    \n",
    "    # Concatenate different pooling strategies\n",
    "    pooled = tf.keras.layers.Concatenate()([max_pool, avg_pool])\n",
    "    pooled = Dropout(0.3)(pooled)\n",
    "    \n",
    "    # Additional features input\n",
    "    features_input = Input(shape=(X_numeric_all_np.shape[1],), name='features_input')\n",
    "    \n",
    "    # Concatenate text features with additional features\n",
    "    concat = tf.keras.layers.Concatenate()([pooled, features_input])\n",
    "    \n",
    "    # Dense layers for classification\n",
    "    dense = Dense(128, activation='relu')(concat)\n",
    "    dense = Dropout(0.4)(dense)\n",
    "    dense = Dense(64, activation='relu')(dense)\n",
    "    dense = Dropout(0.3)(dense)\n",
    "    \n",
    "    # Output layer\n",
    "    output = Dense(1, activation='sigmoid', dtype='float32')(dense)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=[text_input, features_input], outputs=output)\n",
    "    \n",
    "    # Compile with Adam optimizer\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"\\nPerforming 5-fold cross-validation for BiLSTM with Attention...\")\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "y_full_np = y_full.values\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "fold_accuracy = []\n",
    "fold_f1 = []\n",
    "fold_precision = []\n",
    "fold_recall = []\n",
    "\n",
    "# Implement cross-validation for deep learning model\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_padded_all, y_full_np)):\n",
    "    print(f\"\\nTraining fold {fold + 1}/{N_FOLDS}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_text_train_fold = X_padded_all[train_idx]\n",
    "    X_numeric_train_fold = X_numeric_all_np[train_idx]\n",
    "    y_train_fold = y_full_np[train_idx]\n",
    "    \n",
    "    X_text_val_fold = X_padded_all[val_idx]\n",
    "    X_numeric_val_fold = X_numeric_all_np[val_idx]\n",
    "    y_val_fold = y_full_np[val_idx]\n",
    "    \n",
    "    # Build and compile model\n",
    "    model = build_bilstm_attention_model()\n",
    "    \n",
    "    # Callbacks for early stopping and learning rate reduction\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=0.0001)\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        [X_text_train_fold, X_numeric_train_fold], \n",
    "        y_train_fold,\n",
    "        validation_data=([X_text_val_fold, X_numeric_val_fold], y_val_fold),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred_proba = model.predict([X_text_val_fold, X_numeric_val_fold])\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_val_fold, y_pred)\n",
    "    f1 = f1_score(y_val_fold, y_pred, average='macro')\n",
    "    precision = precision_score(y_val_fold, y_pred, average='macro')\n",
    "    recall = recall_score(y_val_fold, y_pred, average='macro')\n",
    "    \n",
    "    # Append metrics\n",
    "    fold_accuracy.append(acc)\n",
    "    fold_f1.append(f1)\n",
    "    fold_precision.append(precision)\n",
    "    fold_recall.append(recall)\n",
    "    \n",
    "    # Report results for this fold\n",
    "    print(f\"Fold {fold + 1} - Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
    "    print(classification_report(y_val_fold, y_pred))\n",
    "\n",
    "# Calculate and report average cross-validation metrics\n",
    "bilstm_cv_accuracy = np.mean(fold_accuracy)\n",
    "bilstm_cv_f1 = np.mean(fold_f1)\n",
    "bilstm_cv_precision = np.mean(fold_precision)\n",
    "bilstm_cv_recall = np.mean(fold_recall)\n",
    "\n",
    "bilstm_cv_accuracy_std = np.std(fold_accuracy)\n",
    "bilstm_cv_f1_std = np.std(fold_f1)\n",
    "\n",
    "print(\"\\nBiLSTM with Attention - Cross-Validation Results:\")\n",
    "print(f\"CV Accuracy: {bilstm_cv_accuracy:.4f} (±{bilstm_cv_accuracy_std:.4f})\")\n",
    "print(f\"CV Macro F1 Score: {bilstm_cv_f1:.4f} (±{bilstm_cv_f1_std:.4f})\")\n",
    "print(f\"CV Macro Precision: {bilstm_cv_precision:.4f}\")\n",
    "print(f\"CV Macro Recall: {bilstm_cv_recall:.4f}\")\n",
    "\n",
    "# Train one final model on all data for later use in ensemble\n",
    "final_bilstm_model = build_bilstm_attention_model()\n",
    "final_bilstm_model.fit(\n",
    "    [X_padded_all, X_numeric_all_np],\n",
    "    y_full_np,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='loss', patience=2, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='loss', factor=0.5, patience=1, min_lr=0.0001)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot performance across folds\n",
    "plt.figure(figsize=(10, 6))\n",
    "folds = [f\"Fold {i+1}\" for i in range(N_FOLDS)]\n",
    "metrics = pd.DataFrame({\n",
    "    'Fold': folds,\n",
    "    'Accuracy': fold_accuracy,\n",
    "    'F1 Score': fold_f1\n",
    "})\n",
    "\n",
    "plt.subplot(111)\n",
    "metrics.plot(x='Fold', y=['Accuracy', 'F1 Score'], kind='bar', ax=plt.gca())\n",
    "plt.title('BiLSTM Performance Across Folds')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim([0.7, 1.0])\n",
    "plt.axhline(y=bilstm_cv_accuracy, color='blue', linestyle='--', \n",
    "           label=f'Mean Accuracy: {bilstm_cv_accuracy:.3f}')\n",
    "plt.axhline(y=bilstm_cv_f1, color='orange', linestyle='--',\n",
    "           label=f'Mean F1: {bilstm_cv_f1:.3f}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b2f58",
   "metadata": {},
   "source": [
    "## 7. Model Ensembling with Cross-Validated Models\n",
    "\n",
    "We'll combine multiple cross-validated models to create an ensemble that leverages the strengths of each approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6927818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating Model Ensemble with Cross-Validated Models...\")\n",
    "\n",
    "# Function to perform cross-validation predictions\n",
    "def get_cv_predictions(model, X, y):\n",
    "    \"\"\"\n",
    "    Get out-of-fold predictions for each sample using cross-validation\n",
    "    This simulates how the model would perform on new data\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=CV_RANDOM_STATE)\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        # For models with predict_proba\n",
    "        cv_preds = cross_val_predict(model, X, y, cv=skf, method='predict_proba')\n",
    "        return cv_preds[:, 1]  # Return probability of positive class\n",
    "    else:\n",
    "        # For models without predict_proba (like LinearSVC)\n",
    "        # First calibrate the model to get probabilities\n",
    "        calibrated_model = CalibratedClassifierCV(model, cv=skf)\n",
    "        calibrated_model.fit(X, y)\n",
    "        return calibrated_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Generate cross-validated predictions for each model\n",
    "print(\"Generating cross-validated predictions...\")\n",
    "\n",
    "# Get predictions for traditional ML models\n",
    "lr_preds = get_cv_predictions(optimized_lr, X_enhanced_full, y_full)\n",
    "rf_preds = get_cv_predictions(rf_model, X_context_full, y_full)\n",
    "xgb_preds = get_cv_predictions(xgb_model, X_enhanced_full, y_full)\n",
    "\n",
    "# LinearSVC doesn't have predict_proba, so we'll use a calibrated version\n",
    "calibrated_svm = CalibratedClassifierCV(LinearSVC(\n",
    "    C=1.0, loss='hinge', max_iter=2000, random_state=42, class_weight='balanced'\n",
    "), cv=N_FOLDS)\n",
    "calibrated_svm.fit(X_basic_full, y_full)\n",
    "svm_preds = calibrated_svm.predict_proba(X_basic_full)[:, 1]\n",
    "\n",
    "# For BiLSTM, use the final model trained on all data to get predictions\n",
    "# This is not ideal but deep learning models are computationally expensive to cross-validate multiple times\n",
    "bilstm_preds = final_bilstm_model.predict([X_padded_all, X_numeric_all_np]).flatten()\n",
    "\n",
    "# Create ensemble predictions using weighted voting\n",
    "def ensemble_predictions(pred_arrays, weights, y_true):\n",
    "    \"\"\"\n",
    "    Create weighted ensemble predictions from multiple model predictions\n",
    "    \n",
    "    Parameters:\n",
    "    pred_arrays - List of prediction arrays (probabilities)\n",
    "    weights - List of weights for each model\n",
    "    y_true - Ground truth labels\n",
    "    \n",
    "    Returns:\n",
    "    y_pred - Ensemble predictions\n",
    "    accuracy - Ensemble accuracy\n",
    "    f1 - Ensemble F1 score\n",
    "    precision - Ensemble precision\n",
    "    recall - Ensemble recall\n",
    "    \"\"\"\n",
    "    assert len(pred_arrays) == len(weights), \"Number of prediction arrays and weights must match\"\n",
    "    \n",
    "    # Apply weights to each model's predictions\n",
    "    weighted_sum = np.zeros(len(y_true))\n",
    "    for pred, weight in zip(pred_arrays, weights):\n",
    "        weighted_sum += pred * weight\n",
    "    \n",
    "    # Convert to binary predictions\n",
    "    weighted_pred = (weighted_sum / sum(weights) > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, weighted_pred)\n",
    "    f1 = f1_score(y_true, weighted_pred, average='macro')\n",
    "    precision = precision_score(y_true, weighted_pred, average='macro')\n",
    "    recall = recall_score(y_true, weighted_pred, average='macro')\n",
    "    \n",
    "    return weighted_pred, accuracy, f1, precision, recall\n",
    "\n",
    "# Define weights based on individual model performance\n",
    "# These weights can be adjusted based on the cross-validated performance of each model\n",
    "model_weights = [0.20, 0.15, 0.25, 0.15, 0.25]  # LR, RF, XGB, SVM, BiLSTM\n",
    "\n",
    "# Create ensemble predictions\n",
    "all_preds = [lr_preds, rf_preds, xgb_preds, svm_preds, bilstm_preds]\n",
    "ensemble_pred, ensemble_accuracy, ensemble_f1, ensemble_precision, ensemble_recall = ensemble_predictions(\n",
    "    all_preds,\n",
    "    model_weights,\n",
    "    y_full\n",
    ")\n",
    "\n",
    "print(\"\\nCross-Validated Ensemble Model Results:\")\n",
    "print(f\"Accuracy: {ensemble_accuracy:.4f}\")\n",
    "print(f\"Macro F1 Score: {ensemble_f1:.4f}\")\n",
    "print(f\"Macro Precision: {ensemble_precision:.4f}\")\n",
    "print(f\"Macro Recall: {ensemble_recall:.4f}\")\n",
    "print(classification_report(y_full, ensemble_pred))\n",
    "\n",
    "# Compare all models including ensemble\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Final Model Comparison (Cross-Validation):\")\n",
    "\n",
    "# Add all models to comparison\n",
    "final_models = [\"Logistic Regression\", \"Random Forest\", \"XGBoost\", \"Linear SVM\", \"BiLSTM with Attention\", \"Ensemble\"]\n",
    "final_accuracies = [lr_accuracy, rf_accuracy, xgb_accuracy, svm_accuracy, bilstm_cv_accuracy, ensemble_accuracy]\n",
    "final_f1_scores = [lr_f1, rf_f1, xgb_f1, svm_f1, bilstm_cv_f1, ensemble_f1]\n",
    "\n",
    "final_comparison = pd.DataFrame({\n",
    "    'Model': final_models,\n",
    "    'CV Accuracy': final_accuracies,\n",
    "    'CV F1 Score': final_f1_scores\n",
    "}).sort_values('CV F1 Score', ascending=False)\n",
    "\n",
    "print(final_comparison)\n",
    "\n",
    "# Visualize final comparison\n",
    "plt.figure(figsize=(14, 7))\n",
    "x = np.arange(len(final_models))\n",
    "width = 0.35\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "bars1 = ax.bar(x - width/2, final_accuracies, width, label='CV Accuracy')\n",
    "bars2 = ax.bar(x + width/2, final_f1_scores, width, label='CV F1 Score')\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, bar in enumerate(bars1):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "            \n",
    "for i, bar in enumerate(bars2):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(final_models, rotation=40, ha='right')\n",
    "ax.set_ylim([0.80, 1.0])  # Adjust based on your actual results\n",
    "ax.set_title('Cross-Validated Model Performance Comparison', fontsize=16)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d8b0ea",
   "metadata": {},
   "source": [
    "## 8. Error Analysis and Cross-Validation Insights\n",
    "\n",
    "Let's analyze the predictions from our cross-validated models to understand what types of reviews our models struggle with and identify opportunities for further improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8674a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassified samples by the ensemble\n",
    "misclassified_indices = np.where(ensemble_pred != y_full.values)[0]\n",
    "print(f\"Number of misclassified samples: {len(misclassified_indices)}\")\n",
    "\n",
    "# Get a sample of misclassified instances\n",
    "if len(misclassified_indices) > 0:\n",
    "    sample_size = min(10, len(misclassified_indices))\n",
    "    sample_indices = np.random.choice(misclassified_indices, sample_size, replace=False)\n",
    "    \n",
    "    print(\"\\nSample of misclassified reviews:\")\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        true_label = \"Positive\" if y_full.values[idx] == 1 else \"Negative\"\n",
    "        pred_label = \"Positive\" if ensemble_pred[idx] == 1 else \"Negative\"\n",
    "        \n",
    "        # Get the original review text\n",
    "        original_review = X_all_text.iloc[idx]\n",
    "        review_snippet = original_review[:200] + \"...\"  # First 200 chars for brevity\n",
    "        \n",
    "        print(f\"\\n{i+1}. Review: {review_snippet}\")\n",
    "        print(f\"True label: {true_label}, Predicted: {pred_label}\")\n",
    "        \n",
    "        # Get sentiment scores from different models for this review\n",
    "        print(\"Model predictions:\")\n",
    "        print(f\"- Logistic Regression: {lr_preds[idx]:.4f}\")\n",
    "        print(f\"- Random Forest: {rf_preds[idx]:.4f}\")\n",
    "        print(f\"- XGBoost: {xgb_preds[idx]:.4f}\")\n",
    "        print(f\"- SVM: {svm_preds[idx]:.4f}\")\n",
    "        print(f\"- BiLSTM: {bilstm_preds[idx]:.4f}\")\n",
    "        \n",
    "        # Get VADER sentiment analysis\n",
    "        vader_scores = vader.polarity_scores(original_review)\n",
    "        print(\"\\nVADER sentiment scores:\")\n",
    "        print(f\"- Negative: {vader_scores['neg']:.3f}\")\n",
    "        print(f\"- Neutral: {vader_scores['neu']:.3f}\")\n",
    "        print(f\"- Positive: {vader_scores['pos']:.3f}\")\n",
    "        print(f\"- Compound: {vader_scores['compound']:.3f}\")\n",
    "        \n",
    "        # Get TextBlob sentiment\n",
    "        blob_sentiment = TextBlob(original_review).sentiment\n",
    "        print(f\"TextBlob: Polarity={blob_sentiment.polarity:.2f}, Subjectivity={blob_sentiment.subjectivity:.2f}\")\n",
    "\n",
    "# Feature importance for traditional models\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Feature Importance Analysis\")\n",
    "\n",
    "# For Logistic Regression\n",
    "if hasattr(optimized_lr, 'coef_'):\n",
    "    print(\"\\nTop features for Logistic Regression:\")\n",
    "    feature_names = ngram_tfidf.get_feature_names_out()\n",
    "    \n",
    "    # Get top positive and negative coefficients\n",
    "    coef = optimized_lr.coef_[0]\n",
    "    top_positive_coef = np.argsort(coef)[-20:]\n",
    "    top_negative_coef = np.argsort(coef)[:20]\n",
    "    \n",
    "    print(\"Top positive features (indicating positive sentiment):\")\n",
    "    for idx in reversed(top_positive_coef):\n",
    "        if idx < len(feature_names):  # Ensure index is valid\n",
    "            print(f\"{feature_names[idx]}: {coef[idx]:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop negative features (indicating negative sentiment):\")\n",
    "    for idx in top_negative_coef:\n",
    "        if idx < len(feature_names):  # Ensure index is valid\n",
    "            print(f\"{feature_names[idx]}: {coef[idx]:.4f}\")\n",
    "\n",
    "# For Random Forest\n",
    "if hasattr(rf_model, 'feature_importances_'):\n",
    "    print(\"\\nTop features for Random Forest:\")\n",
    "    feature_names_context = context_tfidf.get_feature_names_out()\n",
    "    \n",
    "    # Get feature importance\n",
    "    importances = rf_model.feature_importances_\n",
    "    top_indices = np.argsort(importances)[-20:]\n",
    "    \n",
    "    for idx in reversed(top_indices):\n",
    "        if idx < len(feature_names_context):  # Text features\n",
    "            print(f\"{feature_names_context[idx]}: {importances[idx]:.4f}\")\n",
    "        else:  # Numeric features\n",
    "            feature_idx = idx - len(feature_names_context)\n",
    "            if feature_idx < len(numeric_features):\n",
    "                print(f\"{numeric_features[feature_idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "# For XGBoost\n",
    "if hasattr(xgb_model, 'feature_importances_'):\n",
    "    print(\"\\nTop features for XGBoost:\")\n",
    "    feature_names = ngram_tfidf.get_feature_names_out()\n",
    "    \n",
    "    # Get feature importance\n",
    "    importances = xgb_model.feature_importances_\n",
    "    top_indices = np.argsort(importances)[-20:]\n",
    "    \n",
    "    for idx in reversed(top_indices):\n",
    "        if idx < len(feature_names):  # Text features\n",
    "            print(f\"{feature_names[idx]}: {importances[idx]:.4f}\")\n",
    "        else:  # Numeric features\n",
    "            feature_idx = idx - len(feature_names)\n",
    "            if feature_idx < len(numeric_features):\n",
    "                print(f\"{numeric_features[feature_idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "# Plot confusion matrix for ensemble model\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_full, ensemble_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix: Ensemble Model (Cross-Validated)\")\n",
    "plt.show()\n",
    "\n",
    "# Analyze model performance on different review types\n",
    "\n",
    "# 1. Analyze by review length\n",
    "review_lengths = df['review_length'].values\n",
    "misclassified_lengths = review_lengths[misclassified_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist([review_lengths, misclassified_lengths], bins=30, \n",
    "         alpha=0.7, label=['All reviews', 'Misclassified reviews'],\n",
    "         density=True)\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Review Lengths for All vs. Misclassified Reviews')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2. Analyze by model agreement\n",
    "model_predictions = np.column_stack([\n",
    "    (lr_preds > 0.5).astype(int),\n",
    "    (rf_preds > 0.5).astype(int),\n",
    "    (xgb_preds > 0.5).astype(int),\n",
    "    (svm_preds > 0.5).astype(int),\n",
    "    (bilstm_preds > 0.5).astype(int)\n",
    "])\n",
    "\n",
    "# Count how many models agree for each sample\n",
    "agreement_counts = np.sum(model_predictions == model_predictions[:, 0].reshape(-1, 1), axis=1)\n",
    "\n",
    "# Calculate accuracy by agreement level\n",
    "agreement_levels = list(range(1, 6))  # 1 to 5 models\n",
    "accuracy_by_agreement = []\n",
    "\n",
    "for level in agreement_levels:\n",
    "    # Find samples where exactly 'level' models agree\n",
    "    level_indices = np.where(agreement_counts == level)[0]\n",
    "    if len(level_indices) > 0:\n",
    "        # Calculate accuracy for these samples\n",
    "        accuracy = accuracy_score(y_full.values[level_indices], ensemble_pred[level_indices])\n",
    "        accuracy_by_agreement.append(accuracy)\n",
    "    else:\n",
    "        accuracy_by_agreement.append(0)\n",
    "\n",
    "# Plot accuracy by agreement level\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(agreement_levels, accuracy_by_agreement)\n",
    "plt.xlabel('Number of Models in Agreement')\n",
    "plt.ylabel('Ensemble Accuracy')\n",
    "plt.title('Ensemble Accuracy by Model Agreement Level')\n",
    "plt.xticks(agreement_levels)\n",
    "for i, acc in enumerate(accuracy_by_agreement):\n",
    "    plt.text(i + 1, acc + 0.01, f'{acc:.3f}', ha='center')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.show()\n",
    "\n",
    "# 3. Analyze by sentiment ambiguity (using VADER sentiment scores)\n",
    "# Calculate sentiment ambiguity as how close the compound score is to 0\n",
    "sentiment_ambiguity = np.abs(df['vader_compound'].values)\n",
    "misclassified_ambiguity = sentiment_ambiguity[misclassified_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist([sentiment_ambiguity, misclassified_ambiguity], bins=30, \n",
    "         alpha=0.7, label=['All reviews', 'Misclassified reviews'],\n",
    "         density=True)\n",
    "plt.xlabel('Sentiment Strength (abs of VADER compound)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Sentiment Strength for All vs. Misclassified Reviews')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9288f91",
   "metadata": {},
   "source": [
    "## 9. Conclusion and Recommendations\n",
    "\n",
    "Our improved approach with 5-fold cross-validation achieved significantly better and more reliable performance estimates through:\n",
    "\n",
    "1. **Enhanced Text Preprocessing**:\n",
    "   - Context-aware preprocessing that preserves negations\n",
    "   - Careful handling of contractions and sentiment-critical words\n",
    "   - Multiple preprocessing strategies for different models\n",
    "\n",
    "2. **Advanced Feature Engineering**:\n",
    "   - Lexicon-based sentiment features (VADER, TextBlob)\n",
    "   - N-gram features (unigrams, bigrams, trigrams)\n",
    "   - Statistical text features (lengths, punctuation patterns)\n",
    "\n",
    "3. **5-Fold Cross-Validation for Reliable Performance Estimation**:\n",
    "   - More robust performance metrics that better reflect real-world performance\n",
    "   - Reduced risk of overfitting to a specific test set\n",
    "   - Better understanding of model variability across different data splits\n",
    "\n",
    "4. **Optimized Models**:\n",
    "   - Hyperparameter tuning for traditional ML models\n",
    "   - Deep learning models with attention mechanisms\n",
    "   - Transfer learning with state-of-the-art models (RoBERTa)\n",
    "\n",
    "5. **Ensemble Methods**:\n",
    "   - Weighted averaging of multiple cross-validated models\n",
    "   - Leveraging strengths of different model types\n",
    "   - More reliable ensemble predictions through cross-validation\n",
    "\n",
    "The ensemble model outperforms individual models by combining their strengths and compensating for their weaknesses, with performance estimates that better reflect real-world application.\n",
    "\n",
    "**Recommendations for Further Improvements**:\n",
    "\n",
    "1. Add more data or use data augmentation techniques for imbalanced classes\n",
    "2. Try other advanced transformer models like ALBERT or DeBERTa\n",
    "3. Explore task-specific pretraining on a movie review corpus\n",
    "4. Implement more sophisticated ensemble techniques like stacking with cross-validation\n",
    "5. Experiment with multi-modal features by incorporating metadata\n",
    "6. Investigate approaches for handling ambiguous reviews that are difficult to classify"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
