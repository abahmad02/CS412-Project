{
  "best_global_step": 2250,
  "best_metric": 0.6666666666666666,
  "best_model_checkpoint": "./roberta_results/fold_2/checkpoint-2250",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 1.6578260660171509,
      "learning_rate": 4.8911111111111116e-05,
      "loss": 0.7072,
      "step": 50
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 1.4787907600402832,
      "learning_rate": 4.78e-05,
      "loss": 0.7012,
      "step": 100
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 1.4625951051712036,
      "learning_rate": 4.668888888888889e-05,
      "loss": 0.6929,
      "step": 150
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 1.543375849723816,
      "learning_rate": 4.557777777777778e-05,
      "loss": 0.6961,
      "step": 200
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 0.8351913690567017,
      "learning_rate": 4.4466666666666666e-05,
      "loss": 0.7002,
      "step": 250
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.0568697452545166,
      "learning_rate": 4.335555555555556e-05,
      "loss": 0.6988,
      "step": 300
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 2.891860008239746,
      "learning_rate": 4.224444444444445e-05,
      "loss": 0.6943,
      "step": 350
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 1.086025595664978,
      "learning_rate": 4.117777777777778e-05,
      "loss": 0.6823,
      "step": 400
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1889866590499878,
      "learning_rate": 4.006666666666667e-05,
      "loss": 0.7015,
      "step": 450
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 1.1047557592391968,
      "learning_rate": 3.897777777777778e-05,
      "loss": 0.7125,
      "step": 500
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 0.9926535487174988,
      "learning_rate": 3.786666666666667e-05,
      "loss": 0.6126,
      "step": 550
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 1.1659862995147705,
      "learning_rate": 3.675555555555556e-05,
      "loss": 0.6961,
      "step": 600
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 0.7964375615119934,
      "learning_rate": 3.564444444444445e-05,
      "loss": 0.6921,
      "step": 650
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 3.383265972137451,
      "learning_rate": 3.453333333333334e-05,
      "loss": 0.6976,
      "step": 700
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 3.3391001224517822,
      "learning_rate": 3.3422222222222224e-05,
      "loss": 0.6952,
      "step": 750
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 1.025019884109497,
      "learning_rate": 3.231111111111111e-05,
      "loss": 0.6946,
      "step": 800
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 3.3390631675720215,
      "learning_rate": 3.12e-05,
      "loss": 0.6945,
      "step": 850
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.612288236618042,
      "learning_rate": 3.008888888888889e-05,
      "loss": 0.6959,
      "step": 900
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 1.4568709135055542,
      "learning_rate": 2.897777777777778e-05,
      "loss": 0.6963,
      "step": 950
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.7027488946914673,
      "learning_rate": 2.786666666666667e-05,
      "loss": 0.693,
      "step": 1000
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 1.4477168321609497,
      "learning_rate": 2.6755555555555556e-05,
      "loss": 0.6966,
      "step": 1050
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.6307382583618164,
      "learning_rate": 2.5644444444444444e-05,
      "loss": 0.6936,
      "step": 1100
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 0.7748470902442932,
      "learning_rate": 2.4533333333333334e-05,
      "loss": 0.6973,
      "step": 1150
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.4050843715667725,
      "learning_rate": 2.3422222222222222e-05,
      "loss": 0.6938,
      "step": 1200
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 1.363539218902588,
      "learning_rate": 2.2311111111111113e-05,
      "loss": 0.6936,
      "step": 1250
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 2.424842119216919,
      "learning_rate": 2.12e-05,
      "loss": 0.693,
      "step": 1300
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.5767948627471924,
      "learning_rate": 2.008888888888889e-05,
      "loss": 0.6948,
      "step": 1350
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 1.900827407836914,
      "learning_rate": 1.897777777777778e-05,
      "loss": 0.6933,
      "step": 1400
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 2.3145792484283447,
      "learning_rate": 1.7866666666666666e-05,
      "loss": 0.6963,
      "step": 1450
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 2.6538522243499756,
      "learning_rate": 1.6755555555555557e-05,
      "loss": 0.6973,
      "step": 1500
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 1.296582579612732,
      "learning_rate": 1.5644444444444444e-05,
      "loss": 0.696,
      "step": 1550
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.6741997003555298,
      "learning_rate": 1.4533333333333335e-05,
      "loss": 0.6949,
      "step": 1600
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 2.9802544116973877,
      "learning_rate": 1.3422222222222223e-05,
      "loss": 0.6945,
      "step": 1650
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.8443095088005066,
      "learning_rate": 1.2311111111111112e-05,
      "loss": 0.6947,
      "step": 1700
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 2.0661909580230713,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.6954,
      "step": 1750
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.2958084344863892,
      "learning_rate": 1.0088888888888889e-05,
      "loss": 0.6958,
      "step": 1800
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 2.257364273071289,
      "learning_rate": 8.977777777777778e-06,
      "loss": 0.6947,
      "step": 1850
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 1.961400032043457,
      "learning_rate": 7.866666666666667e-06,
      "loss": 0.6962,
      "step": 1900
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 0.6026204824447632,
      "learning_rate": 6.755555555555555e-06,
      "loss": 0.6923,
      "step": 1950
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 1.0841716527938843,
      "learning_rate": 5.6444444444444445e-06,
      "loss": 0.6923,
      "step": 2000
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 0.9647671580314636,
      "learning_rate": 4.533333333333334e-06,
      "loss": 0.695,
      "step": 2050
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.6805084943771362,
      "learning_rate": 3.4222222222222224e-06,
      "loss": 0.6925,
      "step": 2100
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 0.6055983304977417,
      "learning_rate": 2.311111111111111e-06,
      "loss": 0.695,
      "step": 2150
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 1.161771297454834,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.693,
      "step": 2200
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.091892957687378,
      "learning_rate": 8.88888888888889e-08,
      "loss": 0.695,
      "step": 2250
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.5,
      "eval_f1": 0.6666666666666666,
      "eval_loss": 0.693115234375,
      "eval_precision": 0.5,
      "eval_recall": 1.0,
      "eval_runtime": 43.1757,
      "eval_samples_per_second": 208.451,
      "eval_steps_per_second": 13.04,
      "step": 2250
    }
  ],
  "logging_steps": 50,
  "max_steps": 2250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4735998996480000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
