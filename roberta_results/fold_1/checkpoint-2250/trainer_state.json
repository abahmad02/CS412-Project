{
  "best_global_step": 2250,
  "best_metric": 0.8978053646641543,
  "best_model_checkpoint": "./roberta_results/fold_1/checkpoint-2250",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 5.640702724456787,
      "learning_rate": 4.8933333333333335e-05,
      "loss": 0.6694,
      "step": 50
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 16.032596588134766,
      "learning_rate": 4.7866666666666674e-05,
      "loss": 0.564,
      "step": 100
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 15.651932716369629,
      "learning_rate": 4.675555555555556e-05,
      "loss": 0.4496,
      "step": 150
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 13.54069995880127,
      "learning_rate": 4.564444444444444e-05,
      "loss": 0.4665,
      "step": 200
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 4.426267623901367,
      "learning_rate": 4.4533333333333336e-05,
      "loss": 0.4382,
      "step": 250
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 3.867394208908081,
      "learning_rate": 4.3422222222222224e-05,
      "loss": 0.4915,
      "step": 300
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 1.4490197896957397,
      "learning_rate": 4.233333333333334e-05,
      "loss": 0.4933,
      "step": 350
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 7.646783351898193,
      "learning_rate": 4.1222222222222224e-05,
      "loss": 0.4308,
      "step": 400
    },
    {
      "epoch": 0.2,
      "grad_norm": 9.178171157836914,
      "learning_rate": 4.011111111111111e-05,
      "loss": 0.512,
      "step": 450
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 2.508995771408081,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.4132,
      "step": 500
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 54.823631286621094,
      "learning_rate": 3.7888888888888894e-05,
      "loss": 0.4374,
      "step": 550
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 1.4951492547988892,
      "learning_rate": 3.677777777777778e-05,
      "loss": 0.4409,
      "step": 600
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 10.578849792480469,
      "learning_rate": 3.568888888888889e-05,
      "loss": 0.5319,
      "step": 650
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 7.064146518707275,
      "learning_rate": 3.457777777777778e-05,
      "loss": 0.3668,
      "step": 700
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 13.115654945373535,
      "learning_rate": 3.346666666666667e-05,
      "loss": 0.4153,
      "step": 750
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 34.90480041503906,
      "learning_rate": 3.235555555555556e-05,
      "loss": 0.3918,
      "step": 800
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 1.530956506729126,
      "learning_rate": 3.124444444444445e-05,
      "loss": 0.3728,
      "step": 850
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.3023617267608643,
      "learning_rate": 3.0133333333333335e-05,
      "loss": 0.4949,
      "step": 900
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 39.650394439697266,
      "learning_rate": 2.9022222222222223e-05,
      "loss": 0.4224,
      "step": 950
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 4.00129508972168,
      "learning_rate": 2.791111111111111e-05,
      "loss": 0.3733,
      "step": 1000
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 16.320560455322266,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 0.344,
      "step": 1050
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 7.815068244934082,
      "learning_rate": 2.5688888888888892e-05,
      "loss": 0.3659,
      "step": 1100
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 7.803436756134033,
      "learning_rate": 2.457777777777778e-05,
      "loss": 0.359,
      "step": 1150
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.1819292306900024,
      "learning_rate": 2.3466666666666667e-05,
      "loss": 0.3613,
      "step": 1200
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 13.383257865905762,
      "learning_rate": 2.2355555555555558e-05,
      "loss": 0.3476,
      "step": 1250
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 26.0916748046875,
      "learning_rate": 2.1244444444444445e-05,
      "loss": 0.3271,
      "step": 1300
    },
    {
      "epoch": 0.6,
      "grad_norm": 18.782833099365234,
      "learning_rate": 2.0133333333333336e-05,
      "loss": 0.3489,
      "step": 1350
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 20.339210510253906,
      "learning_rate": 1.9022222222222223e-05,
      "loss": 0.3306,
      "step": 1400
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 3.2080676555633545,
      "learning_rate": 1.791111111111111e-05,
      "loss": 0.2726,
      "step": 1450
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 2.195457935333252,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.3353,
      "step": 1500
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 8.363049507141113,
      "learning_rate": 1.568888888888889e-05,
      "loss": 0.3123,
      "step": 1550
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 24.807472229003906,
      "learning_rate": 1.4577777777777778e-05,
      "loss": 0.3181,
      "step": 1600
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 1.6606823205947876,
      "learning_rate": 1.3466666666666666e-05,
      "loss": 0.349,
      "step": 1650
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 4.44698429107666,
      "learning_rate": 1.2355555555555557e-05,
      "loss": 0.2999,
      "step": 1700
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 1.6242107152938843,
      "learning_rate": 1.1244444444444444e-05,
      "loss": 0.3093,
      "step": 1750
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.347025156021118,
      "learning_rate": 1.0133333333333333e-05,
      "loss": 0.2825,
      "step": 1800
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 1.956364393234253,
      "learning_rate": 9.022222222222223e-06,
      "loss": 0.2805,
      "step": 1850
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 14.624470710754395,
      "learning_rate": 7.91111111111111e-06,
      "loss": 0.2707,
      "step": 1900
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 2.9016871452331543,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.2927,
      "step": 1950
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 5.842469215393066,
      "learning_rate": 5.688888888888889e-06,
      "loss": 0.2511,
      "step": 2000
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 7.4679436683654785,
      "learning_rate": 4.5777777777777785e-06,
      "loss": 0.263,
      "step": 2050
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 9.448524475097656,
      "learning_rate": 3.466666666666667e-06,
      "loss": 0.2553,
      "step": 2100
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 7.000801086425781,
      "learning_rate": 2.3555555555555555e-06,
      "loss": 0.2817,
      "step": 2150
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 11.99815559387207,
      "learning_rate": 1.2444444444444445e-06,
      "loss": 0.266,
      "step": 2200
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.878203868865967,
      "learning_rate": 1.3333333333333334e-07,
      "loss": 0.2728,
      "step": 2250
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8975555555555556,
      "eval_f1": 0.8978053646641543,
      "eval_loss": 0.27481138706207275,
      "eval_precision": 0.8956214064573198,
      "eval_recall": 0.9,
      "eval_runtime": 43.3107,
      "eval_samples_per_second": 207.801,
      "eval_steps_per_second": 12.999,
      "step": 2250
    }
  ],
  "logging_steps": 50,
  "max_steps": 2250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4735998996480000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
