{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687e2639",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of IMDB Movie Reviews\n",
    "\n",
    "This notebook performs sentiment analysis on the IMDB movie review dataset.\n",
    "\n",
    "Check and edit notebook here: https://drive.google.com/file/d/1oCf8DUa75G3hPsMYjZmVwIwShaoLLR98/view?usp=sharing\n",
    "\n",
    "**Includes:**\n",
    "- Data Loading and Exploration\n",
    "- Text Preprocessing\n",
    "- Training and Evaluation of:\n",
    "  - Multinomial Naive Bayes\n",
    "  - Logistic Regression\n",
    "  - LSTM (TensorFlow/Keras)\n",
    "- Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf8e40",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d82209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db076221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for missing values and basic stats\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393187f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x='sentiment')\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839812d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Review length analysis\n",
    "df['review_length'] = df['review'].apply(len)\n",
    "print(df['review_length'].describe())\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['review_length'], bins=50)\n",
    "plt.title(\"Review Length Distribution\")\n",
    "plt.xlabel(\"Review Length\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e7e20",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing\n",
    "\n",
    "We clean the text by removing HTML tags, punctuation, converting to lowercase, removing stopwords, and lemmatizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "df['sentiment_label'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "df[['review', 'cleaned_review']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06593b23",
   "metadata": {},
   "source": [
    "## 3. Splitting Data and TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd85602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = df['cleaned_review']\n",
    "y = df['sentiment_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=20000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1364ab",
   "metadata": {},
   "source": [
    "## 4. Training Traditional Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf90e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c03905",
   "metadata": {},
   "source": [
    "## 5. Training LSTM Model (Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ceb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "MAX_WORDS = 20000\n",
    "MAX_LEN = 250\n",
    "EMBEDDING_DIM = 128\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN)\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    Embedding(MAX_WORDS, EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = lstm_model.fit(X_train_pad, y_train,\n",
    "                         validation_split=0.1,\n",
    "                         epochs=10,\n",
    "                         batch_size=128,\n",
    "                         callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b78495",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2714f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, X, y, model_name, is_dl=False):\n",
    "    if is_dl:\n",
    "        y_pred_proba = model.predict(X)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "    else:\n",
    "        y_pred = model.predict(X)\n",
    "        y_pred_proba = model.predict_proba(X)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "    \n",
    "    print(f\"\\nEvaluation for {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y, y_pred):.4f}\")\n",
    "    print(f\"AUC: {roc_auc_score(y, y_pred_proba):.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    sns.heatmap(confusion_matrix(y, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix: {model_name}\")\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(nb_model, X_test_tfidf, y_test, \"Naive Bayes\")\n",
    "evaluate_model(lr_model, X_test_tfidf, y_test, \"Logistic Regression\")\n",
    "evaluate_model(lstm_model, X_test_pad, y_test, \"LSTM\", is_dl=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea132d2",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Comparison\n",
    "\n",
    "- **Naive Bayes**: Fast, interpretable, good baseline.\n",
    "- **Logistic Regression**: Strong performance with TF-IDF, excellent balance of simplicity and accuracy.\n",
    "- **LSTM**: Handles sequence better, potentially more accurate with further tuning.\n",
    "\n",
    "Final thoughts: For quick and reliable sentiment analysis, Logistic Regression with TF-IDF is highly effective. For deeper NLP tasks, LSTM and transformers can offer performance gains."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
