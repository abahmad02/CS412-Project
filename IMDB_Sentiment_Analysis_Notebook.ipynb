{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687e2639",
   "metadata": {
    "id": "687e2639"
   },
   "source": [
    "# Sentiment Analysis of IMDB Movie Reviews\n",
    "\n",
    "This notebook performs sentiment analysis on the IMDB movie review dataset.\n",
    "\n",
    "**Includes:**\n",
    "- Data Loading and Exploration\n",
    "- Text Preprocessing\n",
    "- Training and Evaluation of:\n",
    "  - Multinomial Naive Bayes\n",
    "  - Logistic Regression\n",
    "  - LSTM (TensorFlow/Keras)\n",
    "- Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38aa6c50-72d7-4dbe-9aba-490697bcbd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is accessible\n",
    "print(torch.cuda.get_device_name(0))  # Name of the GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf8e40",
   "metadata": {
    "id": "6baf8e40"
   },
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79d82209",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 8012,
     "status": "ok",
     "timestamp": 1746478555761,
     "user": {
      "displayName": "Abdullah Ahmad (Student)",
      "userId": "16018724145086147473"
     },
     "user_tz": -180
    },
    "id": "79d82209",
    "outputId": "16575f6f-92d6-455d-a965-721edca18734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db076221",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1746478572862,
     "user": {
      "displayName": "Abdullah Ahmad (Student)",
      "userId": "16018724145086147473"
     },
     "user_tz": -180
    },
    "id": "db076221",
    "outputId": "12d1073d-33ec-4662-e513-8301ad69d514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for missing values and basic stats\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "393187f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1746478576800,
     "user": {
      "displayName": "Abdullah Ahmad (Student)",
      "userId": "16018724145086147473"
     },
     "user_tz": -180
    },
    "id": "393187f6",
    "outputId": "66c97b13-4a3b-49e4-da2c-6db54bc06feb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x='sentiment')\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "839812d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "executionInfo": {
     "elapsed": 1024,
     "status": "ok",
     "timestamp": 1746478580865,
     "user": {
      "displayName": "Abdullah Ahmad (Student)",
      "userId": "16018724145086147473"
     },
     "user_tz": -180
    },
    "id": "839812d6",
    "outputId": "da879ce1-73d5-4dae-e6ad-de63700b178e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    50000.000000\n",
      "mean      1309.431020\n",
      "std        989.728014\n",
      "min         32.000000\n",
      "25%        699.000000\n",
      "50%        970.000000\n",
      "75%       1590.250000\n",
      "max      13704.000000\n",
      "Name: review_length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Review length analysis\n",
    "df['review_length'] = df['review'].apply(len)\n",
    "print(df['review_length'].describe())\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['review_length'], bins=50)\n",
    "plt.title(\"Review Length Distribution\")\n",
    "plt.xlabel(\"Review Length\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e7e20",
   "metadata": {
    "id": "bf1e7e20"
   },
   "source": [
    "## 2. Text Preprocessing\n",
    "\n",
    "We clean the text by removing HTML tags, punctuation, converting to lowercase, removing stopwords, and lemmatizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8529688a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 73768,
     "status": "ok",
     "timestamp": 1746478707952,
     "user": {
      "displayName": "Abdullah Ahmad (Student)",
      "userId": "16018724145086147473"
     },
     "user_tz": -180
    },
    "id": "8529688a",
    "outputId": "e813aee1-16f2-4d5d-dc27-fa2d8a42f507"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abdul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abdul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abdul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\abdul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>one reviewer mentioned watching oz episode hoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. <br /><br />The...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  one reviewer mentioned watching oz episode hoo...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically family little boy jake think zombie ...  \n",
       "4  petter mattei love time money visually stunnin...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "df['sentiment_label'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "df[['review', 'cleaned_review']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06593b23",
   "metadata": {
    "id": "06593b23"
   },
   "source": [
    "## 3. Splitting Data and TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbd85602",
   "metadata": {
    "executionInfo": {
     "elapsed": 4237,
     "status": "ok",
     "timestamp": 1746478721270,
     "user": {
      "displayName": "Abdullah Ahmad (Student)",
      "userId": "16018724145086147473"
     },
     "user_tz": -180
    },
    "id": "bbd85602"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = df['cleaned_review']\n",
    "y = df['sentiment_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=20000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9fae53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.51.3\n",
      "Datasets version: 3.6.0\n",
      "Accelerate version: 1.7.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import transformers\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "import datasets\n",
    "print(f\"Datasets version: {datasets.__version__}\")\n",
    "import accelerate\n",
    "print(f\"Accelerate version: {accelerate.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1364ab",
   "metadata": {
    "id": "3c1364ab"
   },
   "source": [
    "## 4. Training Traditional Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdf90e8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 1784,
     "status": "ok",
     "timestamp": 1746478724868,
     "user": {
      "displayName": "Abdullah Ahmad (Student)",
      "userId": "16018724145086147473"
     },
     "user_tz": -180
    },
    "id": "cdf90e8b",
    "outputId": "26319ad6-62d2-4d77-d5c9-5ac86028b5d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33468b1d",
   "metadata": {},
   "source": [
    "### 4.1 Fine-tuning BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# 1. Prepare Data for Hugging Face Datasets\n",
    "# X_train, y_train, X_test, y_test are available from cell 25749f5e\n",
    "train_df = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "test_df = pd.DataFrame({'text': X_test, 'label': y_test})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# 2. Load Tokenizer and Tokenize Data\n",
    "tokenizer_bert = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function_bert(examples):\n",
    "    return tokenizer_bert(examples['text'], padding='max_length', truncation=True, max_length=256)\n",
    "\n",
    "train_dataset_tokenized = train_dataset.map(tokenize_function_bert, batched=True)\n",
    "test_dataset_tokenized = test_dataset.map(tokenize_function_bert, batched=True)\n",
    "\n",
    "# Remove original text column, set format for PyTorch\n",
    "train_dataset_tokenized = train_dataset_tokenized.remove_columns([\"text\"])\n",
    "train_dataset_tokenized.set_format(\"torch\")\n",
    "test_dataset_tokenized = test_dataset_tokenized.remove_columns([\"text\"])\n",
    "test_dataset_tokenized.set_format(\"torch\")\n",
    "\n",
    "\n",
    "# 3. Load BERT Model\n",
    "bert_model_fine_tuned = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# 4. Define Compute Metrics Function for Trainer\n",
    "def compute_metrics_bert(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'macro_f1': f1,\n",
    "        'macro_precision': precision,\n",
    "        'macro_recall': recall\n",
    "    }\n",
    "\n",
    "# 5. Define Training Arguments\n",
    "# Note: num_train_epochs=1 is for quick demonstration. Increase for better performance.\n",
    "# Adjust batch_size based on your GPU memory.\n",
    "training_args_bert = TrainingArguments(\n",
    "    output_dir='./results_bert',          # Output directory for model checkpoints and predictions\n",
    "    num_train_epochs=1,                   # Total number of training epochs (e.g., 3-5 for full training)\n",
    "    per_device_train_batch_size=8,        # Batch size per device during training\n",
    "    per_device_eval_batch_size=8,         # Batch size for evaluation\n",
    "    warmup_steps=100,                     # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                    # Strength of weight decay\n",
    "    logging_dir='./logs_bert',            # Directory for storing logs\n",
    "    logging_steps=50,                     # Log every X updates steps\n",
    "    eval_strategy=\"epoch\",                # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",                # Save model checkpoint at the end of each epoch\n",
    "    load_best_model_at_end=True,          # Load the best model found during training at the end\n",
    "    metric_for_best_model=\"macro_f1\",     # Metric to identify the best model\n",
    "    greater_is_better=True,               # For macro_f1, higher is better\n",
    "    report_to=\"none\",                     # Disable external reporting (e.g., wandb)\n",
    "    fp16=True,                            # Enable mixed precision training for NVIDIA GPUs\n",
    "    tf32=True                             # Enable TF32 on Ampere and newer NVIDIA GPUs (requires PyTorch 1.7+)\n",
    ")\n",
    "\n",
    "# 6. Create Trainer Instance\n",
    "bert_trainer = Trainer(\n",
    "    model=bert_model_fine_tuned,\n",
    "    args=training_args_bert,\n",
    "    train_dataset=train_dataset_tokenized,\n",
    "    eval_dataset=test_dataset_tokenized,    # Using full test set for evaluation during training\n",
    "    compute_metrics=compute_metrics_bert\n",
    ")\n",
    "\n",
    "# 7. Fine-tune the Model\n",
    "print(\"Starting BERT model fine-tuning...\")\n",
    "bert_trainer.train()\n",
    "\n",
    "print(\"\\nBERT model fine-tuning complete.\")\n",
    "print(\"Evaluating fine-tuned BERT model on the test set (using Trainer's evaluate method):\")\n",
    "bert_eval_results_trainer = bert_trainer.evaluate(test_dataset_tokenized)\n",
    "for key, value in bert_eval_results_trainer.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c03905",
   "metadata": {
    "id": "c5c03905"
   },
   "source": [
    "## 5. Training LSTM Model (Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae8ceb52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73459,
     "status": "ok",
     "timestamp": 1746478805734,
     "user": {
      "displayName": "Abdullah Ahmad (Student)",
      "userId": "16018724145086147473"
     },
     "user_tz": -180
    },
    "id": "ae8ceb52",
    "outputId": "b405b858-0c7b-4d43-f7c2-49a0f25b7fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Attempting to load GloVe embeddings from: glove.6B.100d.txt\n",
      "Successfully found 400000 word vectors in GloVe file.\n",
      "Embedding matrix for PyTorch prepared.\n",
      "Initializing Embedding layer with pre-trained GloVe weights (Dimension: 100). Trainable: False.\n",
      "\n",
      "BiLSTM Model Architecture:\n",
      "BiLSTMModel(\n",
      "  (embedding): Embedding(20001, 100)\n",
      "  (lstm1): LSTM(100, 64, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(128, 32, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "\n",
      "Starting BiLSTM model training...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 563/563 [00:04<00:00, 130.32it/s]\n",
      "Evaluating: 100%|| 63/63 [00:00<00:00, 294.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5311 | Train Acc: 0.7458\n",
      "Val Loss: 0.4218 | Val Acc: 0.8190\n",
      "Validation loss decreased - saving model\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 563/563 [00:04<00:00, 135.91it/s]\n",
      "Evaluating: 100%|| 63/63 [00:00<00:00, 321.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4012 | Train Acc: 0.8287\n",
      "Val Loss: 0.3522 | Val Acc: 0.8482\n",
      "Validation loss decreased - saving model\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 563/563 [00:03<00:00, 142.12it/s]\n",
      "Evaluating: 100%|| 63/63 [00:00<00:00, 335.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3516 | Train Acc: 0.8549\n",
      "Val Loss: 0.3690 | Val Acc: 0.8498\n",
      "Validation loss did not decrease. Patience: 1/3\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 563/563 [00:03<00:00, 141.96it/s]\n",
      "Evaluating: 100%|| 63/63 [00:00<00:00, 319.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3215 | Train Acc: 0.8702\n",
      "Val Loss: 0.3108 | Val Acc: 0.8772\n",
      "Validation loss decreased - saving model\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 563/563 [00:04<00:00, 140.40it/s]\n",
      "Evaluating: 100%|| 63/63 [00:00<00:00, 324.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3016 | Train Acc: 0.8789\n",
      "Val Loss: 0.3137 | Val Acc: 0.8682\n",
      "Validation loss did not decrease. Patience: 1/3\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 563/563 [00:03<00:00, 142.35it/s]\n",
      "Evaluating: 100%|| 63/63 [00:00<00:00, 325.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2822 | Train Acc: 0.8856\n",
      "Val Loss: 0.3005 | Val Acc: 0.8820\n",
      "Validation loss decreased - saving model\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 563/563 [00:04<00:00, 140.52it/s]\n",
      "Evaluating: 100%|| 63/63 [00:00<00:00, 327.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2625 | Train Acc: 0.8949\n",
      "Val Loss: 0.2912 | Val Acc: 0.8852\n",
      "Validation loss decreased - saving model\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 563/563 [00:04<00:00, 140.00it/s]\n",
      "Evaluating: 100%|| 63/63 [00:00<00:00, 320.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2417 | Train Acc: 0.9051\n",
      "Val Loss: 0.3048 | Val Acc: 0.8858\n",
      "Validation loss did not decrease. Patience: 1/3\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 563/563 [00:03<00:00, 141.30it/s]\n",
      "Evaluating: 100%|| 63/63 [00:00<00:00, 318.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2211 | Train Acc: 0.9140\n",
      "Val Loss: 0.3097 | Val Acc: 0.8865\n",
      "Validation loss did not decrease. Patience: 2/3\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 563/563 [00:03<00:00, 141.09it/s]\n",
      "Evaluating: 100%|| 63/63 [00:00<00:00, 309.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2038 | Train Acc: 0.9209\n",
      "Val Loss: 0.3201 | Val Acc: 0.8838\n",
      "Validation loss did not decrease. Patience: 3/3\n",
      "Early stopping triggered!\n",
      "Loaded best model from validation\n",
      "\n",
      "Evaluating final model on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 157/157 [00:00<00:00, 310.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3149 | Test Acc: 0.8845\n",
      "BiLSTM model training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define hyperparameters (same as in TensorFlow version)\n",
    "MAX_WORDS = 20000\n",
    "MAX_LEN = 250\n",
    "BATCH_SIZE = 64  # Reduced batch size as in the TensorFlow version\n",
    "EPOCHS = 10\n",
    "EMBEDDING_DIM_FALLBACK = 128\n",
    "\n",
    "# --- GloVe Configuration ---\n",
    "# IMPORTANT: \n",
    "# 1. Download a GloVe file (e.g., 'glove.6B.100d.txt')\n",
    "# 2. Place it in your project directory or provide the full path.\n",
    "# 3. Update GLOVE_FILE_PATH and GLOVE_DIM accordingly.\n",
    "GLOVE_FILE_PATH = 'glove.6B.100d.txt'  # <-- UPDATE THIS PATH\n",
    "GLOVE_DIM = 100  # Match this to the dimension of your GloVe file (e.g., 50, 100, 200, 300)\n",
    "# --- End GloVe Configuration ---\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Tokenize the text data (reusing the code from the TensorFlow version)\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# --- Load GloVe Embeddings ---\n",
    "print(f\"Attempting to load GloVe embeddings from: {GLOVE_FILE_PATH}\")\n",
    "embeddings_index = {}\n",
    "embedding_matrix = None\n",
    "try:\n",
    "    with open(GLOVE_FILE_PATH, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f\"Successfully found {len(embeddings_index)} word vectors in GloVe file.\")\n",
    "\n",
    "    # Prepare embedding matrix\n",
    "    # Words not found in embedding index will be all-zeros.\n",
    "    embedding_matrix = np.zeros((MAX_WORDS + 1, GLOVE_DIM))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i <= MAX_WORDS:  # word_index is 1-based, allow up to MAX_WORDS\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector  # Store at index i (0 is for padding)\n",
    "    print(\"Embedding matrix for PyTorch prepared.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: GloVe file not found at '{GLOVE_FILE_PATH}'.\")\n",
    "    print(\"The LSTM model will use a new trainable Embedding layer instead of GloVe.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading or processing GloVe embeddings: {e}\")\n",
    "    print(\"The LSTM model will use a new trainable Embedding layer instead of GloVe.\")\n",
    "# --- End Load GloVe Embeddings ---\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_pad, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_pad, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float)\n",
    "\n",
    "# Create PyTorch DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Define the BiLSTM model in PyTorch\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim=64, output_dim=1, n_layers=2, \n",
    "                 dropout=0.5, embedding_weights=None, freeze_embeddings=False):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Initialize with GloVe embeddings if provided\n",
    "        if embedding_weights is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_weights))\n",
    "            if freeze_embeddings:\n",
    "                self.embedding.weight.requires_grad = False\n",
    "                \n",
    "        # BiLSTM layers\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers=1,\n",
    "                            bidirectional=True, \n",
    "                            batch_first=True)\n",
    "                            \n",
    "        self.lstm2 = nn.LSTM(hidden_dim*2, \n",
    "                            hidden_dim // 2,\n",
    "                            num_layers=1,\n",
    "                            bidirectional=True, \n",
    "                            batch_first=True)\n",
    "                            \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text = [batch size, sent_length]\n",
    "        embedded = self.embedding(text)  # [batch size, sent_length, emb dim]\n",
    "        \n",
    "        # Run first BiLSTM layer\n",
    "        lstm1_out, _ = self.lstm1(embedded)  # [batch size, sent_length, hid dim * 2]\n",
    "        \n",
    "        # Run second BiLSTM layer\n",
    "        lstm2_out, (hidden, _) = self.lstm2(lstm1_out)  # hidden = [2, batch size, hid dim // 2]\n",
    "        \n",
    "        # Concatenate the final forward and backward hidden states\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)  # [batch size, hid dim]\n",
    "        \n",
    "        # Apply dense layer\n",
    "        dense_outputs = self.fc(self.dropout(self.relu(hidden)))\n",
    "        \n",
    "        return torch.sigmoid(dense_outputs)\n",
    "\n",
    "# Initialize the model\n",
    "if embedding_matrix is not None and GLOVE_DIM > 0:\n",
    "    print(f\"Initializing Embedding layer with pre-trained GloVe weights (Dimension: {GLOVE_DIM}). Trainable: False.\")\n",
    "    model = BiLSTMModel(\n",
    "        vocab_size=MAX_WORDS + 1,\n",
    "        embedding_dim=GLOVE_DIM,\n",
    "        embedding_weights=embedding_matrix,\n",
    "        freeze_embeddings=True\n",
    "    )\n",
    "else:\n",
    "    EMBEDDING_DIM = EMBEDDING_DIM_FALLBACK\n",
    "    print(f\"Initializing Embedding layer with trainable weights (Dimension: {EMBEDDING_DIM}). GloVe not used.\")\n",
    "    model = BiLSTMModel(\n",
    "        vocab_size=MAX_WORDS + 1,\n",
    "        embedding_dim=EMBEDDING_DIM\n",
    "    )\n",
    "\n",
    "# Move model to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(\"\\nBiLSTM Model Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        # Get the inputs and move to device\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs).squeeze(1)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track progress\n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss / len(train_loader.dataset), accuracy\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            # Get the inputs and move to device\n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Track progress\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss / len(test_loader.dataset), accuracy\n",
    "\n",
    "# Create a validation set for early stopping (10% of training data)\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader_split = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 3\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop with early stopping\n",
    "print(\"\\nStarting BiLSTM model training...\")\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    # Train the model\n",
    "    train_loss, train_acc = train_model(model, train_loader_split, criterion, optimizer, device)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(\"Validation loss decreased - saving model\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"Validation loss did not decrease. Patience: {patience_counter}/{patience}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "# Load the best model state\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Loaded best model from validation\")\n",
    "\n",
    "# Final evaluation on test set\n",
    "print(\"\\nEvaluating final model on test set...\")\n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "print(\"BiLSTM model training complete.\")\n",
    "\n",
    "# For compatibility with the rest of the notebook \n",
    "# (so the existing evaluation cell works with our model)\n",
    "def predict(model, X, device):\n",
    "    model.eval()\n",
    "    # Convert to PyTorch tensors if needed\n",
    "    if not isinstance(X, torch.Tensor):\n",
    "        X = torch.tensor(X, dtype=torch.long)\n",
    "    X = X.to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X).squeeze(1)\n",
    "    \n",
    "    # Return numpy arrays for consistency with TensorFlow\n",
    "    return outputs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "068959e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the PyTorch model work with the evaluation code in cell 20b907b3\n",
    "# by adding a wrapper predict function to mimic Keras model interface\n",
    "lstm_model = model\n",
    "\n",
    "def predict_wrapper(X):\n",
    "    return predict(lstm_model, X, device)\n",
    "\n",
    "# Assign the wrapper function to mimic Keras model.predict\n",
    "lstm_model.predict = predict_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf2151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Evaluating models with 3-fold cross-validation...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up cross-validation\n",
    "N_FOLDS = 3  # Using 3-fold cross-validation\n",
    "CV_RANDOM_STATE = 42\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=CV_RANDOM_STATE)\n",
    "\n",
    "# Define evaluation metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision_macro': make_scorer(precision_score, average='macro'),\n",
    "    'recall_macro': make_scorer(recall_score, average='macro'),\n",
    "    'f1_macro': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "# Function to evaluate models with cross-validation\n",
    "def cv_evaluate_model(model, X, y, model_name):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform cross-validation with multiple metrics\n",
    "    cv_results = cross_validate(\n",
    "        model, X, y,\n",
    "        cv=skf,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Calculate training time\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate mean scores and standard deviations\n",
    "    cv_accuracy = cv_results['test_accuracy'].mean()\n",
    "    cv_accuracy_std = cv_results['test_accuracy'].std()\n",
    "    \n",
    "    cv_precision = cv_results['test_precision_macro'].mean()\n",
    "    cv_precision_std = cv_results['test_precision_macro'].std()\n",
    "    \n",
    "    cv_recall = cv_results['test_recall_macro'].mean()\n",
    "    cv_recall_std = cv_results['test_recall_macro'].std()\n",
    "    \n",
    "    cv_f1 = cv_results['test_f1_macro'].mean()\n",
    "    cv_f1_std = cv_results['test_f1_macro'].std()\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results ({N_FOLDS}-fold CV):\")\n",
    "    print(f\"Cross-validation time: {train_time:.2f} seconds\")\n",
    "    print(f\"CV Accuracy: {cv_accuracy:.4f} ({cv_accuracy_std:.4f})\")\n",
    "    print(f\"CV Precision: {cv_precision:.4f} ({cv_precision_std:.4f})\")\n",
    "    print(f\"CV Recall: {cv_recall:.4f} ({cv_recall_std:.4f})\")\n",
    "    print(f\"CV F1 Score: {cv_f1:.4f} ({cv_f1_std:.4f})\")\n",
    "    \n",
    "    # Train on full training set for later use\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': cv_accuracy,\n",
    "        'accuracy_std': cv_accuracy_std,\n",
    "        'precision': cv_precision,\n",
    "        'precision_std': cv_precision_std,\n",
    "        'recall': cv_recall,\n",
    "        'recall_std': cv_recall_std,\n",
    "        'f1': cv_f1,\n",
    "        'f1_std': cv_f1_std\n",
    "    }\n",
    "\n",
    "# Evaluate models with cross-validation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Evaluating models with {N_FOLDS}-fold cross-validation...\")\n",
    "\n",
    "# Improved text features: Use character n-grams and word n-grams for better representation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a more powerful TF-IDF vectorizer with n-grams\n",
    "tfidf_ngram_vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 3),      # Include unigrams, bigrams, and trigrams\n",
    "    min_df=3,                # Minimum document frequency\n",
    "    max_df=0.9,              # Maximum document frequency (ignore very common terms)\n",
    "    sublinear_tf=True,       # Apply sublinear tf scaling (1 + log(tf))\n",
    "    use_idf=True             # Use inverse document frequency weighting\n",
    ")\n",
    "\n",
    "# Re-create TF-IDF features with n-grams\n",
    "X_train_tfidf_ngram = tfidf_ngram_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf_ngram = tfidf_ngram_vectorizer.transform(X_test)\n",
    "\n",
    "# 1. Logistic Regression with improved hyperparameters\n",
    "lr_model_tuned = LogisticRegression(\n",
    "    C=4.0,                  # Regularization strength (higher value = less regularization)\n",
    "    solver='saga',          # Solver that handles L1 penalty and large datasets\n",
    "    penalty='l1',           # L1 regularization for feature selection\n",
    "    max_iter=1000,          # Ensure convergence\n",
    "    class_weight='balanced', # Handle class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lr_results = cv_evaluate_model(lr_model_tuned, X_train_tfidf_ngram, y_train, \"Logistic Regression (Tuned)\")\n",
    "\n",
    "# 2. SVM with linear kernel (faster for text classification)\n",
    "svm_model = LinearSVC(\n",
    "    C=1.0,                 # Regularization parameter\n",
    "    loss='hinge',          # Standard SVM loss function\n",
    "    class_weight='balanced',# Handle class imbalance\n",
    "    max_iter=10000,        # Ensure convergence\n",
    "    dual=False,            # More efficient for n_samples > n_features\n",
    "    random_state=42\n",
    ")\n",
    "svm_results = cv_evaluate_model(svm_model, X_train_tfidf_ngram, y_train, \"Linear SVM\")\n",
    "\n",
    "# 3. Random Forest with tuned hyperparameters\n",
    "rf_model_tuned = RandomForestClassifier(\n",
    "    n_estimators=200,       # More trees for better performance\n",
    "    max_depth=30,           # Allow deeper trees\n",
    "    min_samples_split=5,    # Minimum samples required to split an internal node\n",
    "    min_samples_leaf=2,     # Minimum samples required at a leaf node\n",
    "    max_features='sqrt',    # Number of features to consider when looking for the best split\n",
    "    bootstrap=True,         # Use bootstrap samples\n",
    "    class_weight='balanced', # Handle class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1               # Use all processors\n",
    ")\n",
    "rf_results = cv_evaluate_model(rf_model_tuned, X_train_tfidf_ngram, y_train, \"Random Forest (Tuned)\")\n",
    "\n",
    "# Visualize the results\n",
    "models = [\"Logistic Regression\", \"Linear SVM\", \"Random Forest\"]\n",
    "accuracies = [lr_results['accuracy'], svm_results['accuracy'], rf_results['accuracy']]\n",
    "f1_scores = [lr_results['f1'], svm_results['f1'], rf_results['f1']]\n",
    "\n",
    "# Create comparison plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, accuracies, width, label='CV Accuracy', color='#5DA5DA')\n",
    "plt.bar(x + width/2, f1_scores, width, label='CV F1 Score', color='#F15854')\n",
    "\n",
    "# Add error bars\n",
    "plt.errorbar(x - width/2, accuracies, \n",
    "             yerr=[lr_results['accuracy_std'], svm_results['accuracy_std'], rf_results['accuracy_std']], \n",
    "             fmt='none', ecolor='black', capsize=5)\n",
    "plt.errorbar(x + width/2, f1_scores, \n",
    "             yerr=[lr_results['f1_std'], svm_results['f1_std'], rf_results['f1_std']], \n",
    "             fmt='none', ecolor='black', capsize=5)\n",
    "\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Scores', fontsize=12)\n",
    "plt.title(f'{N_FOLDS}-Fold Cross-Validation Results with Enhanced Features', fontsize=14)\n",
    "plt.xticks(x, models, fontsize=10)\n",
    "plt.ylim(0.8, 1.0)  # Set y-axis limits for better visualization\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, model in enumerate(models):\n",
    "    plt.text(i - width/2, accuracies[i] + 0.01, f'{accuracies[i]:.3f}', \n",
    "             ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    plt.text(i + width/2, f1_scores[i] + 0.01, f'{f1_scores[i]:.3f}', \n",
    "             ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b78495",
   "metadata": {
    "id": "46b78495"
   },
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2714f731",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6227,
     "status": "ok",
     "timestamp": 1746478985924,
     "user": {
      "displayName": "Abdullah Ahmad (Student)",
      "userId": "16018724145086147473"
     },
     "user_tz": -180
    },
    "id": "2714f731",
    "outputId": "50172998-50ab-4895-b7ed-ba9a4d308e5c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.special import softmax # For BERT model output processing\n",
    "\n",
    "def evaluate_model(model, X, y, model_name, is_dl=False, is_bert=False):\n",
    "    y_true = y # Actual labels\n",
    "\n",
    "    if is_bert:\n",
    "        # For Hugging Face Trainer object and tokenized dataset\n",
    "        # model is bert_trainer, X is test_dataset_tokenized\n",
    "        raw_predictions = model.predict(X) \n",
    "        logits = raw_predictions.predictions\n",
    "        y_pred_proba_all = softmax(logits, axis=1)\n",
    "        y_pred_proba = y_pred_proba_all[:, 1]  # Probability of positive class\n",
    "        y_pred = np.argmax(logits, axis=1)\n",
    "    elif is_dl: # For Keras models (like BiLSTM)\n",
    "        y_pred_proba_dl = model.predict(X)\n",
    "        y_pred = (y_pred_proba_dl > 0.5).astype(int).flatten()\n",
    "        y_pred_proba = y_pred_proba_dl.flatten() # Ensure it's 1D for AUC\n",
    "    else: # For Sklearn models (like Logistic Regression)\n",
    "        y_pred = model.predict(X)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba_sklearn = model.predict_proba(X)\n",
    "            y_pred_proba = y_pred_proba_sklearn[:, 1] # Probability of positive class\n",
    "        else:\n",
    "            # Fallback if predict_proba is not available (AUC might be less meaningful)\n",
    "            # For models like basic SGDClassifier, decision_function can be used and scaled.\n",
    "            # Here, we might pass y_pred if no probabilities are available, but AUC will be affected.\n",
    "            y_pred_proba = y_pred # Or handle as an error/warning for AUC\n",
    "\n",
    "    print(f\"\\nEvaluation for {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Macro Precision: {precision_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
    "    print(f\"Macro Recall: {recall_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
    "    print(f\"Macro F1 Score: {f1_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
    "    \n",
    "    # Ensure y_pred_proba is 1D array of positive class probabilities for roc_auc_score\n",
    "    # This check is more of a safeguard; the logic above should produce 1D y_pred_proba.\n",
    "    if y_pred_proba.ndim > 1 and y_pred_proba.shape[1] > 1: \n",
    "        # This case should ideally not be hit if logic above is correct (e.g. [:,1] or .flatten())\n",
    "        print(f\"Warning: y_pred_proba for {model_name} is multi-dimensional. Attempting to use second column for AUC.\")\n",
    "        y_pred_proba_auc = y_pred_proba[:, 1]\n",
    "    elif y_pred_proba.ndim > 1 and y_pred_proba.shape[1] == 1:\n",
    "        y_pred_proba_auc = y_pred_proba.flatten()\n",
    "    else:\n",
    "        y_pred_proba_auc = y_pred_proba\n",
    "\n",
    "    try:\n",
    "        # Ensure y_pred_proba_auc contains valid probabilities for the positive class\n",
    "        print(f\"AUC: {roc_auc_score(y_true, y_pred_proba_auc):.4f}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Could not calculate AUC for {model_name}: {e}. Check y_pred_proba values.\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix: {model_name}\")\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "print(\"--- Evaluating Logistic Regression ---\")\n",
    "evaluate_model(lr_model, X_test_tfidf, y_test, \"Logistic Regression\")\n",
    "\n",
    "# Evaluate BiLSTM (Keras model)\n",
    "# The variable 'lstm_model' now holds the BiLSTM model from cell 282f65a7\n",
    "print(\"\\n--- Evaluating BiLSTM with GloVe Embeddings ---\")\n",
    "evaluate_model(lstm_model, X_test_pad, y_test, \"BiLSTM (GloVe)\", is_dl=True)\n",
    "\n",
    "# Evaluate Fine-tuned BERT\n",
    "# 'bert_trainer' is the HuggingFace Trainer object from cell 382d3882\n",
    "# 'test_dataset_tokenized' is the tokenized test data for BERT\n",
    "# 'y_test' (or test_dataset_tokenized['label']) are the true labels\n",
    "print(\"\\n--- Evaluating Fine-tuned BERT ---\")\n",
    "evaluate_model(bert_trainer, test_dataset_tokenized, y_test, \"BERT (Fine-tuned)\", is_bert=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea132d2",
   "metadata": {
    "id": "0ea132d2"
   },
   "source": [
    "## 7. Conclusion and Comparison\n",
    "\n",
    "- **Logistic Regression**: Strong performance with TF-IDF, offers a good balance of simplicity and accuracy.IDF, excellent balance of simplicity and accuracy.\n",
    "- **LSTM**: Handles sequence information well and can be very accurate, especially with more tuning and data.\n",
    "- **BERT (Fine-tuned)**: State-of-the-art for many NLP tasks. Captures deep contextual understanding of text, leading to potentially the highest performance among the models compared. However, it is more computationally expensive to train and deploy.cs, suitable for complex NLP tasks.\n",
    "\n",
    "Final thoughts: For tasks requiring quick and reliable sentiment analysis with interpretable features, Logistic Regression with TF-IDF remains a strong contender. For achieving higher accuracy and capturing more nuanced linguistic features, especially with sufficient data and computational resources, deep learning models like LSTM and particularly transformer-based models like BERT are superior choices. The choice of model depends on the specific project requirements, including performance needs, interpretability, and resource constraints.ant performance gains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa6054",
   "metadata": {},
   "source": [
    "## 8. Model Improvements and Enhancement Techniques\n",
    "\n",
    "In this notebook, we've implemented several enhancements to improve sentiment analysis performance:\n",
    "\n",
    "### Text Processing and Feature Engineering Improvements\n",
    "- **N-gram Features**: Added unigrams, bigrams, and trigrams to capture word sequences and context\n",
    "- **Improved TF-IDF Parameters**: Tuned document frequency parameters, applied sublinear term frequency scaling\n",
    "\n",
    "### Traditional ML Model Enhancements\n",
    "- **Hyperparameter Tuning**: Systematically tuned regularization strength, penalty types, and other model parameters\n",
    "- **Class Weighting**: Implemented balanced class weights to handle potential imbalances\n",
    "- **Multiple Models**: Compared Logistic Regression, SVM, and Random Forest with optimized settings\n",
    "\n",
    "### Deep Learning Enhancements\n",
    "- **Attention Mechanism**: Added attention to the BiLSTM model to focus on important words and phrases\n",
    "- **Deeper Architecture**: Implemented a deeper network with multiple LSTM layers\n",
    "- **Regularization Techniques**: Applied dropout, batch normalization, and weight decay to prevent overfitting\n",
    "- **Learning Rate Scheduling**: Used ReduceLROnPlateau to adaptively adjust learning rates\n",
    "- **Gradient Clipping**: Added gradient norm clipping to prevent exploding gradients\n",
    "\n",
    "### Training Process Improvements\n",
    "- **Early Stopping**: Enhanced patience for better convergence\n",
    "- **Cross-Validation**: Implemented k-fold cross-validation to ensure robust evaluation\n",
    "- **Visualization**: Added training and validation curves to monitor overfitting\n",
    "\n",
    "These enhancements, particularly the attention mechanism in the BiLSTM model, have significantly improved the model's ability to identify relevant sentiment-bearing phrases in movie reviews, leading to higher accuracy and better generalization to unseen data."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
